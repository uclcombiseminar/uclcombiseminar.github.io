---
layout: post
speaker: Thomas Karam
speaker-url: https://sites.google.com/view/thomas-karam
speaker-uni: University of Oxford
title: 11th February 2025
subtitle: Towards an information-theoretic understanding of probabilistic universality
excerpt_separator: <!--more-->
---
In probability and statistical physics, one class of results that is regularly aimed for is that of universality theorems. These results, starting with the central limit theorem, informally state that if the microscopic components of a system are not very dependent, have somewhat similar behaviour and have reasonable behaviour, then the behaviour of the macroscopic system may be described in a simple way regardless of how complex the microscopic behaviour is. The central limit theorem itself has been given entropy-based proofs and has been given an interpretation akin to the second law of thermodynamics: the entropies of the normalised partial sums are non-decreasing and converge to the maximal possible entropy subject to the variance constraint. Even the central limit theorem has however not been understood completely satisfactorily in this way until recently, as the monotonicity of entropy was first established by Artstein, Ball, Barthe, and Naor in 2004 and then given a simplified proof by Courtade in 2016. After discussing the central limit theorem, we will present some reasons to believe that information-theoretic tools could provide a natural framework for the proofs of other universality theorems.
<!--more-->
